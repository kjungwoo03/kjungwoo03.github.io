<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="author" content="Jungwoo Kim">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Jungwoo Kim</title>
  <link rel="shortcut icon" href="" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="style.css">
</head>

<body>
  <!-- Header Section (Name and Profile) -->
  <table style="width:100%;max-width:850px;margin:auto;">
    <tr>
      <td style="padding:0px;">
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p class="name" style="text-align: center; font-weight: bold;">Jungwoo Kim</p>
              <br>
              <p>
                My name is Jungwoo Kim. 
                I am a M.S./Ph.D student at the <a href="https://mcml.yonsei.ac.kr/">MCML Group</a>, under the supervision of Prof. 
                <a href="https://mcml.yonsei.ac.kr/professor/">Prof. Jong-Seok Lee</a>.
              </p>
              <p>
                I have a broad interest in various research areas that utilize machine learning and computer vision.
                Especially, I'm currently interested in <strong>image compression for machine (ICM)</strong> and <strong>Diffusion Models</strong>.
              <p style="text-align:center">
                <a href="mailto:kjungwoo@yonsei.ac.kr">Email</a> &nbsp;/&nbsp;
                <a href="data/Curriculum_Vitae_1011.pdf">CV</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=gusyMHMAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/jungwoo-kim-44a700288/">LinkedIn</a> &nbsp;/&nbsp;
                <a href="https://github.com/kjungwoo03">Github</a>
              </p>
              <br>
              <p style="text-align:center; font-size: 1.1em; font-weight: bold; margin-top: 10px;">
                <em>Open to any collaboration opportunities across related research topics!</em>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/kjungwoo.png">
                <img style="width:80%;max-width:80%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/kjungwoo.png">
              </a>
            </td>
          </tr>
        </table>

        <!-- News -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Recent News</h2>
              <div style="height: 20px;"></div>
              <div style="max-height:180px; overflow-y:auto; border:1px solid #e0e0e0; border-radius:8px; padding:10px; background:#fafbfc;">
                <ul style="margin:0; padding-left:18px; font-size:1em;">
                  <li>
                    <strong>2026.02.</strong>
                    <span style="display:inline-block; width: 6px;"></span>
                    <span>‚úàÔ∏è Attending <strong>IPIU 2026</strong> held in Jeju, Korea.</span>
                  </li>
                  <li>
                    <strong>2026.01.</strong>
                    <span style="display:inline-block; width: 6px;"></span>
                    <span>üî• Newly joined <strong>MAAP Lab</strong> at MODULAB. I'm now expanding my research to Music AI!</span>
                  </li>
                  <li>
                    <strong>2025.12.</strong>
                    <span style="display:inline-block; width: 6px;"></span>
                    <span>üìù A new preprint <strong>PICM-Net</strong> is now released!</span>
                  </li>
                  <li>
                    <strong>2025.09.</strong>
                    <span style="display:inline-block; width: 6px;"></span>
                    <span>‚úàÔ∏è Attending <strong>MMSP 2025</strong> held in Beijing, China. I'm going to present my work <strong>CSAT</strong>!</span>
                  </li>
                  <li>
                    <strong>2025.08.</strong>
                    <span style="display:inline-block; width: 6px;"></span>
                    <span>üìù One paper accepted at <strong>MMSP 2025</strong>!</span>
                  </li>
                  <li>
                    <strong>2025.08.</strong>
                    <span style="display:inline-block; width: 6px;"></span>
                    <span>‚úàÔ∏è Attending <strong>KCCV 2025</strong> held in Busan, Korea.</span>
                  </li>
                  <li>
                    <strong>2025.03.</strong>
                    <span style="display:inline-block; width: 6px;"></span>
                    <span>üî• Joined <strong>MCML Group</strong> at Yonsei University as an Integrated M.S./Ph.D student.</span>
                  </li>
                  <li>
                    <strong>2025.02.</strong>
                    <span style="display:inline-block; width: 6px;"></span>
                    <span>‚úàÔ∏è Attending <strong>KICS Winter Conference 2025</strong> held in Pyeongchang, Korea.</span>
                  </li>
                  <li>
                    <strong>2025.01.</strong>
                    <span style="display:inline-block; width: 6px;"></span>
                    <span>‚úàÔ∏è Attending <strong>IEIE Winter Workshop on Image Understanding</strong> held in Hongcheon, Korea.</span>
                  </li>
                  <li>
                    <strong>2024.12.</strong>
                    <span style="display:inline-block; width: 6px;"></span>
                    <span>üî• Newly launched my homepage!</span>
                  </li>
                  <!-- üí°üéâüìùüîéüìñ‚úàÔ∏è -->
                </ul>
              </div>
            </td>
          </tr>
        </table>
        
        <!-- Education Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Education</h2>
              <p>
                <strong>Yonsei University</strong>, Seoul, Republic of Korea<br>
                <em>M.S./Ph.D student in School of Integrated Technology</em><br>
                <em>Mar. 2025 - Present</em><br>
                <!-- <em style="display: block; text-align: right;">* One year early graduation.</em> -->
              </p>
              <p>
                <strong>Yonsei University</strong>, Seoul, Republic of Korea<br>
                <em>B.S. in School of Integrated Technology (GPA: 3.95 / 4.30)</em><br>
                <em>Mar. 2022 ‚Äì Feb. 2025 </em><br>
                <em style="display: block; text-align: right;">* One year early graduation.</em>
              </p>
            </td>
          </tr>
        </table>

        <!-- Research Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Research Interests</h2>
              <p>
                My primary research goal is <strong>to understand how deep learning models work</strong> and <strong>to utilize them in various research areas</strong>, especially in computer vision.
                So my primary research interest just lies in various topics about machine learning and computer vision, covering my goal.<br><br>
                Currently, I'm interested in <strong>Image Compression for Machine, Diffusion Models, Explainable AI</strong>, etc. In the past, I have also studied Graph Neural Network (GNN), Reinforcement Learning (RL) and Natural Language Processing (NLP), especially about evaluating the performance of large language models.
              </p>
            </td>
          </tr>
        </table>

        <!-- Publication Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Publications</h2>
              <p style="margin-bottom: 10px;">
                <!-- <strong>Legend:</strong>  -->
                <span style="background-color: #e8f4fd; padding: 2px 6px; border-radius: 3px; font-size: 0.9em;"><strong>P</strong></span> Preprints &nbsp;
                <span style="background-color: #fff2cc; padding: 2px 6px; border-radius: 3px; font-size: 0.9em;"><strong>C</strong></span> Conference Papers &nbsp;
                <span style="background-color: #d5e8d4; padding: 2px 6px; border-radius: 3px; font-size: 0.9em;"><strong>J</strong></span> Journal Papers
              </p>
              <table style="width:100%;margin:auto;">
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <!-- <img src="images/picm.png" alt="PICM-Net" width="160" height="160"> -->
                    <img src="" alt="To be updated" width="160" height="160" style="background-color: #f0f0f0; display: flex; align-items: center; justify-content: center; color: #666; font-size: 14px;">
                  </td>
                  <td width="75%" valign="middle">
                    <span style="background-color: #e8f4fd; padding: 2px 6px; border-radius: 3px; font-size: 0.9em;"><strong>P1</strong></span>
                    <a href="https://arxiv.org/abs/2512.20070">
                      <span class="papertitle">Progressive Learned Image Compression for Machine Perception</span>
                    </a>
                    <br>
                    <strong><u>Jungwoo Kim</u></strong>, Jun-Hyuk Kim, Jong-Seok Lee
                    <br>
                    <em>Arxiv Preprint</em>
                    <p>
                      This paper proposes <strong>the first machine-oriented progressive learned image codec, PICM-Net</strong>, with machine-aware prioritizations and adaptive decoding controller to maintain the desired confidence of downstream machine vision tasks.
                    </p>
                    <p>
                      <!-- <em> Our code is available at <a href="https://github.com/kjungwoo03/Sorting-Matters">here</a>.</em> -->
                       <em> Our code will be available soon.</em>
                    </p>
                  </td>
                </tr>
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/csat.png" alt="CSAT" width="160" height="160">
                  </td>
                  <td width="75%" valign="middle">
                    <span style="background-color: #fff2cc; padding: 2px 6px; border-radius: 3px; font-size: 0.9em;"><strong>C2</strong></span>
                    <!-- <br> -->
                    <a href="https://www.arxiv.org/abs/2508.08920">
                      <span class="papertitle"> Exploring Cross-Stage Adversarial Transferability in Class-Incremental Continual Learning</span>
                    </a>
                    <br>
                    <strong><u>Jungwoo Kim</u></strong>, Jong-Seok Lee
                    <br>
                    <em>The 27th IEEE International Workshop on Multimedia Signal Processing (MMSP 2025)</em>
                    <p>
                      This paper investigates <strong>stage-transferred attacks in class-incremental continual learning (CSAT)</strong>, showing that adversarial examples generated from earlier-stage models remain effective against later-stage models. 
                    </p>
                    <p>
                      <em> Our code is available at <a href="https://github.com/kjungwoo03/CSAT">here</a>.</em>
                    </p>
                  </td>
                </tr>
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/hae-rae.png" alt="HAE-RAE Bench" width="160" height="160">
                  </td>
                  <td width="75%" valign="middle">
                    <span style="background-color: #fff2cc; padding: 2px 6px; border-radius: 3px; font-size: 0.9em;"><strong>C1</strong></span>
                    <a href="https://arxiv.org/abs/2309.02706">
                      <span class="papertitle">HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models</span>
                    </a>
                    <br>
                    Guijin Son, Hanwool Lee, Suwan Kim, Huiseo Kim, Jaecheol Lee, Je Won Yeom, Jihyu Jung, <strong><u>Jungwoo Kim</u></strong>, Songseong Kim
                    <br>
                    <em>Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)</em>
                    <p>
                      HAE-RAE Bench evaluates <strong>large language models' understanding of Korean culture</strong>, offering a challenge beyond traditional English-based benchmarks.
                    </p>
                    <p>
                      <em> Our dataset is available at <a href="https://huggingface.co/datasets/HAERAE-HUB/HAE_RAE_BENCH_1.1">HAERAE-HUB</a>.</em>
                    </p>
                  </td>
                </tr>  
              </table>
            </td>
          </tr>
        </table>

        <!-- Projects Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Projects</h2>
              <table style="width:100%;margin:auto;">
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/petnow.png" alt="Monocular Dog Body Length Estimation" width="160" height="160">                 
                  </td>
                  <td width="75%" valign="middle">
                      <span class="papertitle">Monocular Dog Body Length Estimation</span>
                    </a>
                    <p>
                      <em>This work is part of 24-2 Yonsei DSL Corporate Project supported by <a href="https://www.petnow.io/ko">PetNow</a>, <a href="https://www.seoulaihub.kr/index.asp">Seoul AI Hub</a>, and advised by Prof. <a href="https://dslab-with.github.io/web/#dslab-about">Taeyoung Park</a>.</em>
                    </p>
                    <p>
                      Improving a dog body length estimation model. Based on pose estimation and depth estimation models, we improve <strong>2d-to-3d transformation</strong> with camera intrinsic parameters.
                    </p>
                    <p>
                      <em>Due to security issues, the materials cannot be disclosed.</em>
                    </p>
                  </td>
                </tr>
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/dsl.png" alt="DSL" width="120" height="120" style="padding:20px;">
                  </td>
                  <td width="75%" valign="middle">
                    <span class="papertitle">Audio Sentiment Classification</span>
                    <p>
                      <em>This work is part of 24-1 Yonsei DSL Corporate Project supported by WesomE.</em>
                    </p>
                    <p>
                      Developing a lightweight model (under 500MB) for recognizing emotions from speaker's voice data, focusing on feature augmentation through analyzing <strong>high-frequency details</strong>.
                    </p>
                    <p>
                      <em>Due to security issues, the materials cannot be disclosed.</em>
                    </p>
                  </td>
                </tr>
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/next-level.png" alt="Next Level" width="160" height="160">
                  </td>
                  <td width="75%" valign="middle">
                    <strong>NextLevel: A Choreography Generation Model with Lyric Understanding</strong>
                    <p>
                      <em>This work is part of 23-2 Software Project (IIT4204) with Jaeho Jin, Sangjoon Yeo, and advised by Prof. <a href="https://sites.google.com/site/jeonggilko">JeongGil Ko</a>.</em>
                    </p>
                    <p>
                      Integrating lyric understanding into group choreography generation model.
                      By <strong>incorporating text embedding into previous diffusion-based models</strong>, we generate lyric-aware dance motions.
                    </p>
                    <p>
                      <em>Our materials aren't disclosed now.</em>
                    </p>
                  </td>
                </tr>
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/red-cnn.png" alt="Medical Image Super Resolution" width="160" height="160" style="padding:5px;">
                  </td>
                  <td width="75%" valign="middle">
                    <span class="papertitle">Medical Image Super Resolution</span>
                    <p>
                      <em>Implementation of <a href="https://arxiv.org/abs/1702.00288">Low-Dose CT with a Residual Encoder-Decoder Convolutional Neural Network</a>. 
                        This work is a part of the internship in <a href="https://sites.google.com/view/yonsei-medisyslab/home">Medisys Lab</a>, advised by Prof. <a href="https://sites.google.com/view/yonsei-medisyslab/members/professor">Jongduk Baek</a>.</em>
                    </p>
                    <p>
                      The research focus on <strong>enhancing low-dose CT images</strong> by super-resolving them to match the quality of normal-dose images. 
                      Additionally, as a follow-up study, we replaced the architecture with a U-Net to further evaluate the effectiveness in preserving details.
                    </p>
                    <p>
                      <em>Our code is available <a href="https://github.com/kjungwoo03/SUPER_RESOLUTION_RED_CNN">here</a>.</em>
                    </p>
                  </td>
                </tr>               
              </table>
            </td>
          </tr>
        </table>

        <!-- Honors and Awards Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Honors and Awards</h2>
              <p>
                <strong>Best Project Award, 2024-2 DSL Modeling Project</strong><br>
                <em>2024-2 DSL Modeling Project Presentation (2024.09.24.) held by Yonsei Data Science Lab.</em>
                <br>
                <em> Topic: An Unified Framework for Group Choreography Dataset Collection</em>
                <br>
              </p>
              <p>
                <strong>Certification, 4th LG Aimers/Data Intelligence</strong><br>
                <em>LG Aimers (Advancing AI for Young Talents): Online AI Education and Hackaton (2024.01.02. ~ 2024.02.26.) held by LG AI Research.</em>
              </p>
              <p>
                <strong>Excellence Award, 2023 Yonsei Medical Convergence Challenge</strong><br>
                <em>Yonsei Medical Convergence Challenge (2023.01.30. ~ 2023.01.31.) held by The Medical Scientist Training Program.</em>
                <br>
                <em>Our presentation is available <a href="data/ecg_final_template.pdf" target="_blank">here</a>.</em>
              </p>
            </td>
          </tr>
        </table>
        <!-- Academic Service Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Academic Services</h2>
              <p>
                <strong>
                  Reviewer
                </strong><br> <em>ICASSP 2026</em>
              </p>
            </td>
          </tr>
        </table>

        <!-- Talk Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Invited Talks</h2>
              <p>
                <strong>Learned Image Compression and Computer Vision</strong><br>
                <em> 2025 Summer Alumni Seminar in Yonsei DSL - Aug 21, 2025</em><br>
              </p>
              <p>
                <strong>ML101: From Scratch to Deep Learning</strong><br>
                <em>2025 Summer Field Research with <a href="https://iasa.icehs.kr/main.do">Incheon Academy of Science and Arts (IASA)</a> - Jul, 2025</em><br>
              </p>
              <p>
                <strong>Diffusion: From DDPM to Stable Diffusion</strong><br>
                <em>25-1 Regular Session Speech in Yonsei DSL (video available <a href="https://www.youtube.com/watch?v=vDX8GtuHp9s">here</a>) - Mar 18, 2025</em><br>
              </p>
              <p>
                <strong>Normalizing Flow and Energy Based Model</strong><br>
                <em>24-2 Regular Session Speech in Yonsei DSL (video available <a href="https://youtu.be/9PG_iqlH3J8?si=SVaR3PiKTenUfLo7">here</a>) - Sep 03, 2024</em><br>
              </p>
              <p>
                <strong>Mamba Review: Linear-Time Sequence Modeling with Selective State Spaces</strong><br>
                <em>24-2 Regular Session Speech in Yonsei DSL (video available <a href="https://youtu.be/Vm6oFFXoP74?si=9HtctY6BKEQqEVYt">here</a>) - Aug 22, 2024</em><br>
              </p>
              <p>
                <strong>Life as a Researcher in Engineering</strong><br>
                <em>(Invited) Yeungnam High School, Daegu, Republic of Korea - Mar 16, 2024</em><br>
              </p>
            </td>
          </tr>
        </table>


        <!-- Teaching Experience Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Teaching Assistant</h2>
              <p> 
                <strong>Understanding the World with Data (YCS1012)</strong><br>
                <em>Fall 2025</em><br>
              </p>
              <p> 
                <strong>Advanced Mathematics 2 (IIT2102)</strong><br>
                <em>Spring 2025</em><br>
              </p>
              <p> 
                <strong>Computational Thinking and SW Programming (YCS1001)</strong><br>
                <em>Fall 2025, Winter 2024, Fall 2024, Summer 2024, Spring 2024, Spring 2023</em><br>
              </p>
              <p>
                <strong>Mechatronics Project (IIT4312)*</strong><br>
                <em>Spring 2024</em><br>
                <em style="display: block; text-align: right;">* Via tutoring program hosted by Yonsei University.</em>
              </p>
            </td>
          </tr>
        </table>

        <!-- Miscellanea Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Miscellanea</h2>
              <p>
                <strong>MAAP Lab, Modulab</strong><br>
                <em>Senior Researcher (Jan. 2026 - Present)</em><br>
                <a href="https://huggingface.co/m-a-a-p"> MAAP (Music AI Assemble People!) Lab</a> is a non-commercial research group at MODULAB, led by <a href="https://junst.github.io/">Junyoung Koh</a>.
                MAAP Lab focuses on advancing the foundations of Music AI through practical research, then sharing results openly with the community.
              </p>
              <p>
                <strong>Yonsei Data ScienceLab</strong><br>
                <em>11th Regular Member (Dec. 2023 - Dec. 2024)</em><br>
                <em>Head of Academic Team (Jun. 2024 - Dec. 2024)</em><br>
                <a href="https://www.notion.so/Data-Science-Lab-dcc313da82774e7cb62fe76c2ad09d86">Yonsei Data Science Lab (DSL)</a> is a student community under the Department of Applied Statistics at Yonsei University, advised by Prof. <a href="https://dslab-with.github.io/web/#dslab-about">Taeyoung Park</a>. 
                Yonsei DSL focus on studying and applying various theories related to Data Science and Machine Learning, based on a statistical theory.
              </p>

              <p>
                <strong>ElutherAI</strong><br>
                <em>Project Member (Sep. 2023 - Nov. 2023)</em><br>
                <a href="https://www.eleuther.ai/">Eluther AI</a> is a non-profit AI research lab founded in 2020. ElutherAI focuses on the interpretability and alignment of Large Language Models.
              </p>

              <p>
                <strong>Yonsei Computer Club</strong><br>
                <em>Regular Member (Sep. 2022 - Aug. 2025)</em><br>
                <em>Member of Friendship Team (Jul. 2024 - Dec. 2024)</em><br>
                <a href="https://www.ycc.club/">Yonsei Computer Club (YCC)</a>, founded in 1970, is the only central computer club at Yonsei University. YCC brings together students with a shared interest in computers and supports a variety of academic activities.
                
              </p>
              <p>
                <strong>Yonsei Engineering Student Council</strong><br>
                <em>Executive Member (Apr. 2022 - Nov. 2023)</em><br>
                <em>Freshman Vice Representative (Mar. 2022 - Feb. 2023)</em><br>
              </p>
            </td>
          </td>
          </tr>
        </table>
        <!-- Footer Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <p style="text-align:center;font-size:small;">
                Last updated on Dec 24, 2025.<br><br>
                ¬© 2025 Jungwoo Kim. All rights reserved. Design and source code adapted from 
                <a href="https://jonbarron.info" style="font-size:small;">Jon Barron's website</a>.
              </p>
            </td>
          </tr>
        </table>

      </td>
    </tr>
  </table>
</body>
</html>