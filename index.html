<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="author" content="Jungwoo Kim">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Jungwoo Kim</title>
  <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="style.css">
</head>

<body>
  <!-- Header Section (Name and Profile) -->
  <table style="width:100%;max-width:800px;margin:auto;">
    <tr>
      <td style="padding:0px;">
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p class="name" style="text-align: center; font-weight: bold;">Jungwoo Kim</p>
              <br>
              <p>
                I am an undergraduate student at the <a href="https://sit.yonsei.ac.kr/sit/index.do">School of Integrated Technology</a>,
                <a href="https://www.yonsei.ac.kr/">Yonsei University</a>. Currently, I am working as a research intern at 
                <a href="https://mcml.yonsei.ac.kr/">MCML Group</a>, advised by Prof. 
                <a href="https://scholar.google.com/citations?user=YGwwt6cAAAAJ&hl=en">Jong-Seok Lee</a>.
              </p>
              <p>
                In the past, I also worked as a research intern at 
                <a href="https://sites.google.com/view/yonsei-medisyslab/home">Medisys Lab</a>, focusing on medical image 
                super-resolution and segmentation using deep learning models. I have a broad interest in various research 
                areas that utilize machine learning and computer vision.
              </p>
              <p style="text-align:center">
                <a href="mailto:kjungwoo@yonsei.ac.kr">Email</a> &nbsp;/&nbsp;
                <a href="data/Curriculum_Vitae_1011.pdf">CV</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=gusyMHMAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/jungwoo-kim-44a700288/">LinkedIn</a> &nbsp;/&nbsp;
                <a href="https://github.com/kjugwoo03/">Github</a>
              </p>
              <br>
              <p style="text-align:center; font-size: 1.1em; font-weight: bold; margin-top: 15px;">
                <em>Open to any collaboration opportunities across related research topics!</em>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/kjungwoo.png">
                <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/kjungwoo.png">
              </a>
            </td>
          </tr>
        </table>

        <!-- Education Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Education</h2>
              <p>
                <strong>Yonsei University</strong>, Seoul, South Korea<br>
                <em>B.S. in School of Integrated Technology (GPA: 3.96 / 4.30)</em><br>
                <em>Mar. 2022 – Feb. 2025 (Expected)</em><br>
                <em style="display: block; text-align: right;">* One year early graduation.</em>
              </p>
            </td>
          </tr>
        </table>

        <!-- Research Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Research Interests</h2>
              <p>
                My primary research goal is <strong>to fully understand how deep learning models work</strong> and <strong>to fully utilize them in various research areas</strong>, especially in computer vision.
                So My primary research interest just lies in various topics about machine learning and computer vision, covering my goal.<br><br>
                Currently, I'm interested in Explainable AI, Generative Models, Efficient Machine Learning, etc. In the past, I have also studied Graph Neural Network (GNN), Reinforcement Learning (RL) and Natural Language Processing (NLP), especially about evaluating the performance of large language models.
              </p>
            </td>
          </tr>
        </table>

        <!-- Publication Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Publications</h2>
              <table style="width:100%;margin:auto;">
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/hae-rae.png" alt="HAE-RAE Bench" width="160" height="160">
                  </td>
                  <td width="75%" valign="middle">
                    <a href="https://aclanthology.org/2024.lrec-main.704">
                      <span class="papertitle">HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models</span>
                    </a>
                    <br>
                    <a href="https://github.com/guijinSON">Guijin Son</a>, 
                    <a href="https://scholar.google.com/citations?user=pDwvcO0AAAAJ&hl=ko">Hanwool Lee</a>,
                    Suwan Kim, Huiseo Kim, Jaecheol Lee, 
                    <a href="https://scholar.google.com/citations?user=UqrTvV0AAAAJ&hl=ko">Je Won Yeom</a>, 
                    Jihyu Jung, 
                    <strong><u>Jungwoo Kim</u></strong>, Songseong Kim
                    <br>
                    <em>Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)</em>
                    <p>
                      HAE-RAE Bench evaluates <strong>large language models' understanding of Korean culture</strong>, offering a challenge beyond traditional English-based benchmarks.
                    </p>
                    <p>
                      <em> Our Dataset is available at <a href="https://huggingface.co/datasets/HAERAE-HUB/HAE_RAE_BENCH_1.1">HAERAE-HUB</a>.</em>
                    </p>
                  </td>
                </tr>
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/k2-eval.png" alt="K2-EVAL" width="160" height="160">
                  </td>
                  <td width="75%" valign="middle">
                    <a href="https://openreview.net/forum?id=BAtM7tcMrm">
                      <span class="papertitle">K2-EVAL: Harnessing the Evaluation of Linguistic Fluency and Ethnolinguistic Knowledge in Korean</span>
                    </a>
                    <br>
                    <a href="https://github.com/guijinSON">Guijin Son</a>, Hyunwoo Ko, Hoyoung Lee, Seunghyeok Hong, Yewon Kim, <strong><u>Jungwoo Kim</u></strong>
                    <br>
                    <em>ACL 2024 Workshop, The 2nd Workshop on Cross-Cultural Considerations in NLP (C3NLP 2024)</em>
                    <p>
                      K2-EVAL introduces a benchmark with 90 handwritten instructions that test knowledge of <strong>Korean language and culture</strong>, including 5400 human annotations to evaluate 32 LLMs. It also examines if GPT-4 can replace human evaluations.
                    </p>
                  </td>
                </tr>                
              </table>
            </td>
          </tr>
        </table>

        <!-- Projects Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Projects</h2>
              <table style="width:100%;margin:auto;">
                <!-- Projects -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/choreography.png" alt="Audio Sentiment Classification" width="160" height="160">
                  </td>
                  <td width="75%" valign="middle">
                    <a href="https://github.com/kjungwoo03/24_2_DSL_Modeling_CV1">
                      <span class="papertitle">Group Choreography Data Crawling Framework</span>
                    </a>
                    <p>
                      <em>This work, <strong>NextLevel2: Neural Extraction and Tracking Framework for K-POP Group Choreography</strong> is part of 24-2 Yonsei DSL Modeling Project.</em>
                    </p>
                    <p>
                      We focus on the research gap that existing group choreography dataset collection methods require manual intervention, and propse a fully-automatic data collection framework.
                      This approach is expected to contribute to the scalability of group choreography dataset creation.
                    </p>
                    <p>
                      <em>Our presentation video is available <a href="https://www.youtube.com/watch?v=sxWe0EJ5Eck&t=1073s">here</a>. Code and Github will be fully released soon.</em>
                    </p>
                  </td>
                </tr>
                <!-- Projects -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/audio-sentiment.png" alt="Audio Sentiment Classification" width="160" height="160">
                  </td>
                  <td width="75%" valign="middle">
                    <a href="https://meteor-microwave-835.notion.site/24-1-DSL-x-WesomE-08a468c84ef94ed3855a464fff58fb32">
                      <span class="papertitle">Audio Sentiment Classification</span>
                    </a>
                    <p>
                      <em>This work is part of 24-1 Yonsei DSL Corporate Project with WesomE.</em>
                    </p>
                    <p>
                      Developed a lightweight model (under 500MB) for recognizing emotions from speaker's voice data, focusing on feature augmentation through analyzing <strong>high-frequency details</strong> of Fast Fourier Transform.
                    </p>
                    <p>
                      <em>Due to security issues, the materials cannot be disclosed. Please contact me if needed.</em>
                    </p>
                  </td>
                </tr>
                <!-- Projects -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/prompt.png" alt="Prompt Engineering" width="160" height="160">
                  </td>
                  <td width="75%" valign="middle">
                    <a href="https://github.com/kjungwoo03/24_1_DSL_Modeling">
                      <span class="papertitle">Prompt Engineering in Image Generation Model</span>
                    </a>
                    <p>
                      <em>This work, <strong>InferPrompt: Reframing Prompt Engineering with BLIP-2</strong>, is part of 24-1 Yonsei DSL Modeling Project.</em>
                    </p>
                    <p>
                      Prompt engineering in text-to-image generation model. We tried to improve the quality of generated image, by <strong>style transferring the inferred prompt</strong>. By adding re-questioning block, we could improve the detail quality of generated image.
                    <p>
                      <em>Our presentation video is available <a href="https://www.youtube.com/watch?v=XKE6IjfMUjg&t=4645s">here</a>. Code and Github will be released soon.</em>
                    </p>
                  </td>
                </tr>
                <!-- Projects -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/next-level.png" alt="Prompt Engineering" width="160" height="160">
                  </td>
                  <td width="75%" valign="middle">
                    <a href="https://github.com/kjungwoo03/24_1_DSL_Modeling">
                      <span class="papertitle">NextLevel: A Choreography Generation Model with Lyric Understanding</span>
                    </a>
                    <p>
                      <em>This work is part of 23-2 Software Project (IIT4204) with Jaeho Jin, Sangjoon Yeo, and advised by Prof. <a href="https://sites.google.com/site/jeonggilko">JeongGil Ko</a>.</em>
                    </p>
                    <p>
                      We tried to represent lyrics into group choreography generation model. By <strong>incorporating text embedding into previous model</strong>, we could generate lyric-aware dance motions.
                    </p>
                    <p>
                      <em>Our materials aren't disclosed now. Please contact me if needed.</em>
                    </p>
                  </td>
                </tr>
                <!-- Projects -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/red-cnn.png" alt="Medical Image Super Resolution" width="160" height="160">
                  </td>
                  <td width="75%" valign="middle">
                    <a href="https://github.com/kjungwoo03/SUPER_RESOLUTION_RED_CNN">
                      <span class="papertitle">Medical Image Super Resolution</span>
                    </a>
                    <p>
                      <em>Implementation of <a href="https://arxiv.org/abs/1702.00288">Low-Dose CT with a Residual Encoder-Decoder Convolutional Neural Network</a>. This work is a part of the project in <a href="https://sites.google.com/view/yonsei-medisyslab/home">Medisys Lab</a>, advised by Prof. <a href="https://sites.google.com/view/yonsei-medisyslab/members/professor">Jongduk Baek</a>.</em>
                    </p>
                    <p>
                      The research focus on <strong>enhancing low-dose CT images by super-resolving</strong> them to match the quality of normal-dose images. Additionally, as a follow-up study, we replaced the original architecture with a U-Net model to further evaluate the effectiveness in preserving image details.
                    </p>
                  </td>
                </tr>
                <!-- Projects -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/coronary.png" alt="Acute Coronary Syndrome Detection" width="160" height="160">
                  </td>
                  <td width="75%" valign="middle">
                    <a href="https://github.com/kjungwoo03/2023-ECG_CHALLENGE">
                      <span class="papertitle">Acute Coronary Syndrome Detection on Wearable Device</span>
                    </a>
                    <p>
                      <em><strong>Won an Award for Excellence</strong> at the 2023 Yonsei Medical Convergence Challenge (with <a href="https://github.com/ChangdaeVictorLee">ChangeDae Lee</a>, Hyelim Kim, YoungJun Na)</em>
                    </p>
                    <p>
                      Developed a ResNet-based deep learning model for <strong>diagnosing acute coronary syndrome using wearable devices</strong>, focusing on detecting the condition using ECG signals from a limited number of leads, optimized for real-world application on wearable platforms.
                    </p>
                    <p>
                      <em>Our presentation template is available <a href="data/ecg_final_template.pdf">here</a>.</em>
                    </p>
                  </td>
                </tr>                               
              </table>
            </td>
          </tr>
        </table>


        <!-- Honors and Awards Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Honors and Awards</h2>
              <p>
                <strong>Excellence Award, 2023 Yonsei Medical Convergence Challenge</strong><br>
                <em>Yonsei Medical Convergence Challenge (2023.01.30. ~ 2023.01.31.) held by The Medical Scientist Training Program(Undergraduate Course)</em>
              </p>
              <p>
                <strong>Various Scholarships</strong><br>
                <em>Detailed information about specific scholarships can be found <a href='data/scholarship_1011.pdf'>here</a>.</em>                
              </p>
            </td>
          </tr>
        </table>


        <!-- Academic Service Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Academic Services</h2>
              <p>
                <em>TBD</em>
              </p>
            </td>
          </tr>
        </table>


        <!-- Talk Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Talks</h2>
              <p>
                <strong>Normalizing Flow and Energy Based Model</strong><br>
                <em>24-2 Regular Session Speech in Yonsei DSL (video available <a href="https://youtu.be/9PG_iqlH3J8?si=SVaR3PiKTenUfLo7">here</a>) - Sep 03, 2024</em><br>
              </p>
              <p>
                <strong>Mamba Review: Linear-Time Sequence Modeling with Selective State Spaces</strong><br>
                <em>24-2 Regular Session Speech in Yonsei DSL (video available <a href="https://youtu.be/Vm6oFFXoP74?si=9HtctY6BKEQqEVYt">here</a>) - Aug 22, 2024</em><br>
              </p>
              <p>
                <strong>Life as a Undergraduate Student in Engineering Field</strong><br>
                <em>(Invited) Yeungnam High School, Daegu, Republic of Korea - Mar 16, 2024</em><br>
              </p>
            </td>
          </tr>
        </table>


        <!-- Teaching Experience Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Teaching Experiences</h2>
              <p>
                <strong>Computational Thinking and SW Programming (YCS1001)</strong><br>
                <em>Fall 2024, Summer 2024, Spring 2024, Spring 2023</em><br>
              </p>
              <p>
                <strong>Mechatronics Project (IIT4312)*</strong><br>
                <em>Spring 2024</em><br>
                <em style="display: block; text-align: right;">* Via tutoring program hosted by Yonsei University.</em>
              </p>
            </td>
          </tr>
        </table>


        <!-- Miscellanea Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <h2>Miscellanea</h2>
              <p>
                <strong>Yonsei Computer Club</strong><br>
                <em>11th Regular Member (Dec. 2023 - Now)</em><br>
                <em>Head of Academic Team (Jun. 2024 - Now)</em><br>
                <a href="https://www.ycc.club/">Yonsei Computer Club (YCC)</a>, founded in 1970, is the only central computer club at Yonsei University. YCC brings together students with a shared interest in computers and supports a variety of activities.
              </p>

              <p>
                <strong>ElutherAI</strong><br>
                <em>Project Member (Sep. 2023 - Nov. 2023)</em><br>
                <a href="https://www.eleuther.ai/">Eluther AI</a> is a non-profit AI research lab founded in 2020. ElutherAI focuses on the interpretability and alignment of Large Language Models.
              </p>

              <p>
                <strong>Yonsei Data Science Lab</strong><br>
                <em>Regular Member (Sep. 2022 - Now)</em><br>
                <em>Member of Friendship Team (Jul. 2024 - Now)</em><br>
                <a href="https://www.notion.so/Data-Science-Lab-dcc313da82774e7cb62fe76c2ad09d86">Yonsei Data Science Lab (DSL)</a> is a student community under the Department of Applied Statistics at Yonsei University, advised by Prof. <a href="https://dslab-with.github.io/web/#dslab-about">Taeyoung Park</a>. 
                Yonsei DSL focus on studying and applying various theories related to Data Science and Machine Learning, based on a statistical theory.
              </p>

              <p>
                <strong>Yonsei Engineering Student Council</strong><br>
                <em>Executive Member (Apr. 2022 - Nov. 2023)</em><br>
                <em>Freshman Vice Representative (Mar. 2022 - Feb. 2023)</em><br>
              </p>
            </td>
          </td>
          </tr>
        </table>


        <!-- Footer Section -->
        <table style="width:100%;margin:auto;">
          <tr>
            <td style="padding:20px;">
              <p style="text-align:center;font-size:small;">
                Last updated on Oct 11, 2024.<br><br>
                © 2024 Jungwoo Kim. All rights reserved. Design and source code adapted from 
                <a href="https://jonbarron.info" style="font-size:small;">Jon Barron's website</a>.
              </p>
            </td>
          </tr>
        </table>

      </td>
    </tr>
  </table>
</body>
</html>
